---
layout: post
title: Convolutional Neural Networks
---

## 介绍一个简单的卷积神经网络模型及对应BP求导过程：
----------------------------------------------------------------------------------

![cnn](https://i.imgur.com/qiFb5Qi.png)

假设上图中输入图片是28\*28\*3大小的图像，一个28\*28大小的矩阵是一个通道。\*3就有三个通道，后面通道也都是这个意思。各层的大小及卷积核大小如下：

* 第一层(input)：28\*28\*3
* 第二层（conv1)：24\*24\*6
* 第三层(pool1)：12\*12\*6
* 第四层(conv2)：8\*8\*12
* 第五层(pool2)：4\*4\*12
* 第六层(fc)：1\*192
* 第七层(out)：1\*10

（虽然写的是第七层，但是其实这只是一个3层的卷积神经网络，因为cnn层数是以卷积层个数来定的。）
 卷积核大小：

* 第一层到第二层：5\*5\*3\*6         # 5\*5表示每一个卷积核大小，个数是3\*6，3代表输入RGB三通道，6是输出通道。
* 第二层到第三层：pooling层，维度不变，大小变为一半（12\*12\*6），没有参数
* 第三层到第四层：5\*5\*6\*12        #输出维度是12
* 第四层到第五层：pooling，输出大小为4\*4\*12，没有参数
* 第五层到第六层：这里只是把pool2层所有元素reshape变为一个向量，大小是4\*4\*12=192，没有参数
* 第六层到第七层：192\*10          #全链接层

## 卷积
_____________________________________________________________________________________
![conv](https://d26dzxoao6i3hh.cloudfront.net/items/3y0P3H2K3F3W2w1r2n2W/Screen%20recording%202017-11-14%20at%2005.02.20%20PM.gif?v=8291e38c)

　　如果输入是一个5\*5\*3大小的RGB图片(即上图x，矩阵大小是[5, 5, 3]),卷积核w大小是[3, 3, 3, 2].
偏执b大小是[1, 1, 2]，输出o大小是[3, 3, 2].输入图片进行卷积之前有两种操作，一个是pad1(就是在每一个通道周围加一圈0)，一种啥也不加还是原图片。所以5\*5\*3加一圈0就是[7, 7, 3]，然后w大小是[3, 3, 3, 2],前面两个[3, 3]是一个卷积核大小，后面[3, 2]是一共3\*2个卷积核，卷积核个数是根据输入和输出通道确定的，一个输入通道和一个输出通道之间就有一个[3,3]的卷积核，并且不同输入输出通道间卷积核是互不相同的。因为输入是3通道，输出是2个通道，所以一共3*2个卷积核。

　　那么输出的第一个通道o[:, :, 0]是怎么算出来的呢。

<img src="https://i.imgur.com/dXTqO6a.png" width = "700" height = "500" alt="ｃ"/>

　ｘ[:,:,0]的[7,7]大小和w[:,:,0,0]的[3,3]做卷积(从[7,7]左上角开始对应的[3,3]个元素和卷积核[3,3]九个元素对应相乘然后相加)，O1=x1\*w1+x2\*w2+x3\*w3+x4\*w4+x5\*w5+x6\*w6+x7\*w7+x8\*w8+x9\*w9得到一个O_01的第一个元素o1，同理得到O_02的第一个元素o1和O_03的o1，将三个o1相加在加上偏执b0(一个输出通道只有一个偏执)就得到了第一个通道输出的第一个元素：

<font color="#FF0000" size = "3px">O1</font>=<font color="#008000" size = "3px">O1</font>+<font color="#0000FF" size = "3px">O1</font>+<font color="#FFFF00" size = "3px">O1</font>+b0

这就得到了o[:,:,0]的第一个元素-3.其他计算一样。然后框向右移动了两格(stride=2的意思)，再次卷积计算即可。
## 神经网络单元
*************************************************************************************
但是上面输出并不是一层卷积的输出，我们还要对o=w\*x+b之后的值经过激励函数，之后的输出才是最后输出。
f=sigmoid(o)  
![neu_model](https://i.imgur.com/GTJqsmm.jpg)
这样f输出才是我们的conv1

## 池化
------------------------------------------------------------------------------------
对应到我们的模型，输入是[28,28,3]，经过上面的卷积得到[24,24,6]的输出。然后是pooling层，两种：
![max_pool](https://i.imgur.com/5G8zoiL.jpg)
max pooling，[2,2]的小框内取一个最大值输出。
ave pooling, [2,2]的4个值取平均输出。

## 全连接
----------------------------------------------------------------------------------
全连接层是192到10的向量映射，out的每一个元素输出相当于192个元素分别乘以192个权重，然后相加，在加上偏执。对输出的10个结果取softmax或者sigmoid得到一个概率输出。就可以判断分类类别。
输出层的每一个数十一个[0,1]的概率分布，我们找到最大的那个对应的位置作为输出。比如dog的标签就是[1,0,0,0,0,0,0,0,0,0]，那么如果我得到的输出向量第一个位置数最大如[0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1],那么就说明这张图片是dog.

## Back Propagation(BP)
----------------------------------------------------------------------------------
具体反向求导过程还有细节可以查看[cnn]()

     
# [github code for cnn numpy python windows](https://github.com/duanyzhi/cnn_numpy)


